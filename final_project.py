# -*- coding: utf-8 -*-
"""FINAL PROJECT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NwtFlUPd04me3aaj_PqZzX3ucvbt7azo

Students: Kevin Ariel Poma Ochoa

Aldo Paul Rios Murillo

Iver Gonzalo Bustamante Claure

Fernando Palomino Sanchez

# FINAL PROJECT

Good quality fruit detector for efficient collection
"""

!pip install -q kaggle

from google.colab import files
files.upload()

!mkdir ~/.kaggle

!cp kaggle.json ~/.kaggle/

!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets list

!kaggle datasets download -d sriramr/fruits-fresh-and-rotten-for-classification

!unzip fruits-fresh-and-rotten-for-classification.zip

!rm fruits-fresh-and-rotten-for-classification.zip

"""https://www.kaggle.com/sriramr/fruits-fresh-and-rotten-for-classification"""

# Commented out IPython magic to ensure Python compatibility.
# Libreries
# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
import torch
from torchvision import datasets, transforms
import torchvision
import os
import sys
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
}

data_dir = 'dataset'
image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),
                                          data_transforms[x])
                  for x in ['test', 'train']}
dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,
                                             shuffle=True, num_workers=4)
              for x in ['test', 'train']}
dataset_sizes = {x: len(image_datasets[x]) for x in ['test', 'train']}
class_names = image_datasets['train'].classes

# Get a batch of training data
inputs, classes = next(iter(dataloaders['train']))

# Denormalise
inputs = ((inputs * 0.229) + 0.485)

# Make a grid from batch
out = torchvision.utils.make_grid(inputs).permute(1,2,0).numpy()
plt.imshow(out)

plt.imshow(out)
print(class_names) # This one have the classes we will clasify
print(dataset_sizes) # Dimensions of both train's and validation's images

print(inputs[0,1].shape)
print("inputs' shape: ",inputs.shape)
plt.imshow(inputs[15,0])

print(image_datasets)

# dataiter = iter(image_datasets)
# images, labels = dataiter.next()
print(inputs.shape) # inputs = images
print(classes.shape) # classes = labels

from torch import nn
from torch import optim
import torch.nn.functional as F

class Network_2(nn.Module):
    def __init__(self):
        super().__init__()
        # Defining the layers, 150528, 128, 64, 6 units each
        self.fc1 = nn.Linear(150528, 128)
        self.fc2 = nn.Linear(128, 64)
        # Output layer, 6 units - one for each digit
        self.fc3 = nn.Linear(64, 6)
        
    def forward(self, x):
        ''' Forward pass through the network, returns the output logits '''
        
        x = self.fc1(x)
        x = F.relu(x)
        x = self.fc2(x)
        x = F.relu(x)
        x = self.fc3(x)
        x = F.softmax(x, dim=1)
        
        return x

model = Network_2()
model

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)

print('Initial weights - ', model.fc1.weight)

inputs, classes = next(iter(dataloaders['train']))
inputs.resize_(16,150528)

# Clear the gradients, do this because gradients are accumulated
optimizer.zero_grad()

# Forward pass, then backward pass, then update weights
output = model.forward(inputs)
loss = criterion(output, classes)
loss.backward()
print('Gradient -', model.fc1.weight.grad)
optimizer.step()

optimizer = optim.SGD(model.parameters(), lr=0.001)

epochs = 60
print_every = 20
steps = 0

for e in range(epochs):
    running_loss = 0
    for inputs, classes in iter(dataloaders['train']):
        steps += 1
        # Flatten QMNIST images into a 150528 long vector
        inputs.resize_(inputs.size()[0], 150528)
        
        optimizer.zero_grad()
        
        # Forward and backward passes
        output = model.forward(inputs)
        loss = criterion(output, classes)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        
        if steps % print_every == 0:
            print("Epoch: {}/{}... ".format(e+1, epochs),
                  "Loss: {:.4f}".format(running_loss/print_every))
            
            running_loss = 0

inputs, classes = next(iter(dataloaders['test']))

img = inputs[0].view(1, 150528)
# Turn off gradients to speed up this part
with torch.no_grad():
    logits = model.forward(img)

# Output of the network are logits, need to take softmax for probabilities
ps = F.softmax(logits, dim=1)

ps = ps.data.numpy().squeeze()

# Show the results
fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)
ax1.imshow(img.resize_( 1, 224, 224).numpy().squeeze())
ax1.axis('off')
ax2.barh(np.arange(6), ps)
ax2.set_aspect(0.1)
ax2.set_yticks(np.arange(6))

ax2.set_yticklabels(np.arange(6))

ax2.set_title('Class Probability')
ax2.set_xlim(0, 1.1)

plt.tight_layout()
pos = ps.tolist()
statefruits = ['Fresh Apple', 'Fresh Banana', 'Fresh Orange', 'Rotten Apple', 'Rotten Banana', 'Rotten Orange']
print(statefruits[pos.index(max(ps))])
if pos.index(max(ps)) <= 2:
  print('Suitable to be harvested and consumed')
else:
  print('Lack of maturity or is in decomposition')

